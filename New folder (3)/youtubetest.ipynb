{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\sneha\\onedrive\\desktop\\youtube data harvesting and warehousing using sql,mongodb and streamlit\\.venv\\lib\\site-packages (2.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Key Connection\n",
    "\n",
    "def Api_connect():\n",
    "    Api_Id = \"AIzaSyD_gjGRNKDxhr7H3EJZq4b9f7F8GvxZ-WQ\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "\n",
    "\n",
    "    youtube = build(api_service_name,api_version,developerKey=Api_Id)\n",
    "    \n",
    "    return youtube\n",
    "youtube = Api_connect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Channel Information\n",
    "def get_channel_info(channel_id):\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "                part = \"snippet,contentDetails,Statistics\",\n",
    "                id = channel_id)\n",
    "            \n",
    "    response1=request.execute()\n",
    "\n",
    "    for i in range(0,len(response1[\"items\"])):\n",
    "        data = dict(\n",
    "                    Channel_Name = response1[\"items\"][i][\"snippet\"][\"title\"],\n",
    "                    Channel_Id = response1[\"items\"][i][\"id\"],\n",
    "                    Subscription_Count= response1[\"items\"][i][\"statistics\"][\"subscriberCount\"],\n",
    "                    Views = response1[\"items\"][i][\"statistics\"][\"viewCount\"],\n",
    "                    Total_Videos = response1[\"items\"][i][\"statistics\"][\"videoCount\"],\n",
    "                    Channel_Description = response1[\"items\"][i][\"snippet\"][\"description\"],\n",
    "                    Playlist_Id = response1[\"items\"][i][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"],\n",
    "                    )\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_details=get_channel_info(\"UCuI5XcJYynHa5k_lqDzAgwQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Channel_Name': 'Data Science Tamil',\n",
       " 'Channel_Id': 'UCuI5XcJYynHa5k_lqDzAgwQ',\n",
       " 'Subscription_Count': '151',\n",
       " 'Views': '9342',\n",
       " 'Total_Videos': '18',\n",
       " 'Channel_Description': 'Dear Brothers and Sisters,\\n\\n         (Please clarify your doubts in Project doubt clarification session)\\n          Really SORRY for the INCONVENIENCE.\\n',\n",
       " 'Playlist_Id': 'UUuI5XcJYynHa5k_lqDzAgwQ'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only 10          :\"UCdP7WjR7SGmo1TBSSUJ5Mtw\"\n",
    "#science with sam :\"UChGd9JY4yMegY6PxqpBjpRA\"\n",
    "#Mr Gk            :\"UC5cY198GU1MQMIPJgMkCJ_Q\"\n",
    "#vicky_edits      :\"UCGx7rPjOTx-Sm8u85KRI1wA\"\n",
    "#madhan gowri     :\"UCY6KjrDBN_tIRFT_QNqQbRQ\"\n",
    "#un signed        :\"UCXnDDUQyJpRfC98_ZRIuhZA\"\n",
    "#naked science    :\"UC8JT2m0mKEgvEtie3JNKwew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get videos ids\n",
    "def get_video_ids(channel_id):\n",
    "    video_ids = []\n",
    "    # get Uploads playlist id\n",
    "    response = youtube.channels().list(id=channel_id, \n",
    "                                  part='contentDetails').execute()\n",
    "    Playlist_Id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        res = youtube.playlistItems().list( \n",
    "                                           part='snippet',\n",
    "                                           playlistId=Playlist_Id, \n",
    "                                           maxResults=500,\n",
    "                                           pageToken=next_page_token).execute()\n",
    "        \n",
    "        for item in res.get('items', []):\n",
    "            video_ids.append(item['snippet']['resourceId']['videoId'])\n",
    "            \n",
    "        next_page_token = res.get('nextPageToken')\n",
    "        \n",
    "        if next_page_token is None:\n",
    "            break\n",
    "\n",
    "    total_video_count = res['pageInfo']['totalResults']\n",
    "    return video_ids\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_Ids=get_video_ids(\"UCuI5XcJYynHa5k_lqDzAgwQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIrc-tFOSrk'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video_Ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get video information\n",
    "def get_video_info(video_ids):\n",
    "\n",
    "    video_data = []\n",
    "    video_details = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        #video_details.extend(response.get(\"items\", []))\n",
    "\n",
    "        for item in response['items']:\n",
    "            data = dict(\n",
    "                Channel_Name=item['snippet']['channelTitle'],\n",
    "                Channel_Id=item['snippet']['channelId'],\n",
    "                Video_Id=item['id'],\n",
    "                Title=item['snippet']['title'],\n",
    "                Tags=item['snippet'].get('tags'),\n",
    "                Thumbnail=item['snippet']['thumbnails']['default']['url'],\n",
    "                Description=item['snippet']['description'],\n",
    "                Published_Date=item['snippet']['publishedAt'],\n",
    "                Duration=item['contentDetails']['duration'],\n",
    "                Views=item['statistics'].get('viewCount'),\n",
    "                Likes=item['statistics'].get('likeCount'),\n",
    "                Comments=item['statistics'].get('commentCount'),\n",
    "                Favorite_Count=item['statistics']['favoriteCount'],\n",
    "                Definition=item['contentDetails']['definition'],\n",
    "                Caption_Status=item['contentDetails']['caption']\n",
    "            )\n",
    "            video_data.append(data)\n",
    "\n",
    "    return video_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details=get_video_info(Video_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get comment information\n",
    "def get_comments_details(video_ids):\n",
    "    comment_data = []\n",
    "    for video_id in video_ids:\n",
    "            try:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part=\"snippet\",\n",
    "                    videoId=video_id,\n",
    "                    maxResults=50\n",
    "                )\n",
    "                response = request.execute()\n",
    "\n",
    "                for item in response.get(\"items\", []):\n",
    "                    comment_information = dict(\n",
    "                        Comment_Id=item[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                        Video_Id=item[\"snippet\"][\"videoId\"],\n",
    "                        Comment_Text=item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"],\n",
    "                        Comment_Author=item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"],\n",
    "                        Comment_Published=item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"]\n",
    "                    )\n",
    "\n",
    "                    comment_data.append(comment_information)\n",
    "\n",
    "            #next_page_token = response.get('nextPageToken')\n",
    "            #if next_page_token is None:\n",
    "                #break\n",
    "            except:\n",
    "                pass\n",
    "    return comment_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get comment information-@\n",
    "def get_comments_details(video_ids):\n",
    "    comment_data = []\n",
    "    try:\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(part=\"snippet,replies\",\n",
    "                                                    videoId=video_ids,\n",
    "                                                    maxResults=10,\n",
    "                                                    pageToken=next_page_token).execute()\n",
    "            for cmt in response['items']:\n",
    "                data = dict(Comment_id = cmt['id'],\n",
    "                            Video_id = cmt['snippet']['videoId'],\n",
    "                            Comment_text = cmt['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                            Comment_author = cmt['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                            Comment_posted_date = cmt['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
    "                            Like_count = cmt['snippet']['topLevelComment']['snippet']['likeCount'],\n",
    "                            Reply_count = cmt['snippet']['totalReplyCount']\n",
    "                           )\n",
    "                comment_data.append(data)\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    return comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIrc-tFOSrk',\n",
       " 'iytmvBg26Vk',\n",
       " 'Lut7ISPuUew',\n",
       " 'OW6S10NFfWU',\n",
       " 'ipSL33FOS30',\n",
       " 'QGzhSqyoUbA',\n",
       " 'vrUniQisKTE',\n",
       " 'VfakvmAlwhU',\n",
       " 'G4YlF8bBtLs',\n",
       " '5TEauiYxpZk',\n",
       " '2IU9RpMzgAo',\n",
       " 'FGnZ3pUliCU',\n",
       " 'EXn3-jKNVFU',\n",
       " 'on-a5-77Y94',\n",
       " 'OM7Bsb9ZCTY',\n",
       " '2cyfmA-R-Uw',\n",
       " 'r2sn478BKg4',\n",
       " 'xBCx4PEZpfo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video_Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_details=get_comments_details(Video_Ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Comment_Id': 'UgxuDpWe_P3r4TdD0pp4AaABAg',\n",
       "  'Video_Id': 'DIrc-tFOSrk',\n",
       "  'Comment_Text': 'Thank you so much',\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-18T12:30:53Z'},\n",
       " {'Comment_Id': 'UgzHZBoyUwaBW0W1Ve54AaABAg',\n",
       "  'Video_Id': 'DIrc-tFOSrk',\n",
       "  'Comment_Text': 'bro, i have same project. can you make the video of complete project.',\n",
       "  'Comment_Author': 'Hari haran',\n",
       "  'Comment_Published': '2023-11-18T06:09:07Z'},\n",
       " {'Comment_Id': 'Ugz8DLn7f4_kltEiNhd4AaABAg',\n",
       "  'Video_Id': 'iytmvBg26Vk',\n",
       "  'Comment_Text': 'Error varuthu bro konjam solliringala broo',\n",
       "  'Comment_Author': 'Amala S',\n",
       "  'Comment_Published': '2023-11-17T09:51:31Z'},\n",
       " {'Comment_Id': 'UgzKIbG7GQqa_NqZQRt4AaABAg',\n",
       "  'Video_Id': 'iytmvBg26Vk',\n",
       "  'Comment_Text': 'Hi bro',\n",
       "  'Comment_Author': 'Amala S',\n",
       "  'Comment_Published': '2023-11-17T09:50:01Z'},\n",
       " {'Comment_Id': 'UgwCXAQd6UkY9z_F_wV4AaABAg',\n",
       "  'Video_Id': 'iytmvBg26Vk',\n",
       "  'Comment_Text': 'Hai bro Thank you so much for your next concept.',\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-16T14:50:43Z'},\n",
       " {'Comment_Id': 'UgwnVTYAGL0YqsSuf3p4AaABAg',\n",
       "  'Video_Id': 'iytmvBg26Vk',\n",
       "  'Comment_Text': 'Superb bro. You explain everything in simplest form thank you.',\n",
       "  'Comment_Author': 'Fake',\n",
       "  'Comment_Published': '2023-11-16T04:54:38Z'},\n",
       " {'Comment_Id': 'UgzSzJ4Bd5-oEwGMEel4AaABAg',\n",
       "  'Video_Id': 'Lut7ISPuUew',\n",
       "  'Comment_Text': \"Bro How can I contact you? I can't able to msg in linked profile. Please give any other solution.\",\n",
       "  'Comment_Author': 'Kaviyavarshi Kaviyavarshi',\n",
       "  'Comment_Published': '2023-11-18T04:05:47Z'},\n",
       " {'Comment_Id': 'UgxAdj3rkEHjnpfnFgB4AaABAg',\n",
       "  'Video_Id': 'Lut7ISPuUew',\n",
       "  'Comment_Text': 'Sql questions query ya run panna Internal Error (Unread result found) nu varuthu bro',\n",
       "  'Comment_Author': 'Kaviyavarshi Kaviyavarshi',\n",
       "  'Comment_Published': '2023-11-16T15:44:55Z'},\n",
       " {'Comment_Id': 'UgzR6jqoERY6YTzW1394AaABAg',\n",
       "  'Video_Id': 'Lut7ISPuUew',\n",
       "  'Comment_Text': 'Bro mysql la video table create paniten, but athula values Insert aaga matithu Insert aagumbothu Error varuthu',\n",
       "  'Comment_Author': 'Kaviyavarshi Kaviyavarshi',\n",
       "  'Comment_Published': '2023-11-14T04:20:07Z'},\n",
       " {'Comment_Id': 'UgzhZRUZ2QesfvyiJTF4AaABAg',\n",
       "  'Video_Id': 'Lut7ISPuUew',\n",
       "  'Comment_Text': 'Bro please explain phonepe project give another playlist 😂 ur video are easily understandable',\n",
       "  'Comment_Author': 'Nishanth Vijay',\n",
       "  'Comment_Published': '2023-11-11T16:25:11Z'},\n",
       " {'Comment_Id': 'UgzFJCYXq53WxOzsgah4AaABAg',\n",
       "  'Video_Id': 'Lut7ISPuUew',\n",
       "  'Comment_Text': 'Bro how to contact you',\n",
       "  'Comment_Author': 'Arjun Mech',\n",
       "  'Comment_Published': '2023-11-11T13:00:53Z'},\n",
       " {'Comment_Id': 'UgyhXP8pfPzwJJlg0Bx4AaABAg',\n",
       "  'Video_Id': 'Lut7ISPuUew',\n",
       "  'Comment_Text': 'Bro im data science student in guvi how can i contact you',\n",
       "  'Comment_Author': 'Vijaya Priyadarshini',\n",
       "  'Comment_Published': '2023-11-11T12:35:02Z'},\n",
       " {'Comment_Id': 'UgyNVZvvtGhXMw10bV94AaABAg',\n",
       "  'Video_Id': 'Lut7ISPuUew',\n",
       "  'Comment_Text': 'Thanks bor',\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-11T02:51:54Z'},\n",
       " {'Comment_Id': 'UgwNZfkY_N3YdSzdlrZ4AaABAg',\n",
       "  'Video_Id': 'OW6S10NFfWU',\n",
       "  'Comment_Text': 'bro final part eppo?',\n",
       "  'Comment_Author': 'itshari',\n",
       "  'Comment_Published': '2023-11-10T07:20:28Z'},\n",
       " {'Comment_Id': 'Ugy4d00oCsjMtPRLbkx4AaABAg',\n",
       "  'Video_Id': 'OW6S10NFfWU',\n",
       "  'Comment_Text': 'Thank you bro. I have seen all your videos. Very useful and even absolute beginning can understand it. Thank you bro',\n",
       "  'Comment_Author': 'Fake',\n",
       "  'Comment_Published': '2023-11-10T04:54:33Z'},\n",
       " {'Comment_Id': 'Ugy74U8PA_2cWXaNOuB4AaABAg',\n",
       "  'Video_Id': 'OW6S10NFfWU',\n",
       "  'Comment_Text': \"That's bro\",\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-10T03:00:44Z'},\n",
       " {'Comment_Id': 'Ugy1j_45w6J5lGfrlwR4AaABAg',\n",
       "  'Video_Id': 'ipSL33FOS30',\n",
       "  'Comment_Text': 'Hi bro. error is coming. Request quota exceeded nu.. epdi overcome panradhu..?',\n",
       "  'Comment_Author': 'Hudson Sylvestor',\n",
       "  'Comment_Published': '2023-11-09T16:27:46Z'},\n",
       " {'Comment_Id': 'UgwdllSLgyhDlYSWQVJ4AaABAg',\n",
       "  'Video_Id': 'ipSL33FOS30',\n",
       "  'Comment_Text': 'bro steamlit part eppo varum bro',\n",
       "  'Comment_Author': 'CHOCO FTW',\n",
       "  'Comment_Published': '2023-11-09T11:19:32Z'},\n",
       " {'Comment_Id': 'UgzH1UuZ7LkvrHfr1U14AaABAg',\n",
       "  'Video_Id': 'ipSL33FOS30',\n",
       "  'Comment_Text': 'Thank you so much bro your channel videos are most useful for me, I learned lots of information  from your videos. Thanks lot',\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-09T05:13:05Z'},\n",
       " {'Comment_Id': 'Ugym6de7VI10_0Ct_QN4AaABAg',\n",
       "  'Video_Id': 'ipSL33FOS30',\n",
       "  'Comment_Text': 'bro next video upload pannunga',\n",
       "  'Comment_Author': 'itshari',\n",
       "  'Comment_Published': '2023-11-09T04:08:51Z'},\n",
       " {'Comment_Id': 'Ugx_ENkAbTtGpSpTlfV4AaABAg',\n",
       "  'Video_Id': 'QGzhSqyoUbA',\n",
       "  'Comment_Text': 'bro what to do if there is duplicate keys error because of channel_id repetiton',\n",
       "  'Comment_Author': 'Gayathri Ramasubramanian',\n",
       "  'Comment_Published': '2023-11-16T21:49:50Z'},\n",
       " {'Comment_Id': 'Ugx2ZdSjZfTmqB2kE1V4AaABAg',\n",
       "  'Video_Id': 'QGzhSqyoUbA',\n",
       "  'Comment_Text': 'Please give number to call',\n",
       "  'Comment_Author': 'prathiba princeton',\n",
       "  'Comment_Published': '2023-11-15T08:11:42Z'},\n",
       " {'Comment_Id': 'UgwL5sziIzaVXoPfeop4AaABAg',\n",
       "  'Video_Id': 'QGzhSqyoUbA',\n",
       "  'Comment_Text': 'bro i get HttpError  when i change the channal id in very function how to solve',\n",
       "  'Comment_Author': 'Prakash Arumugam',\n",
       "  'Comment_Published': '2023-11-05T15:29:44Z'},\n",
       " {'Comment_Id': 'UgyW7GfVHOo93kcu0u14AaABAg',\n",
       "  'Video_Id': 'vrUniQisKTE',\n",
       "  'Comment_Text': 'Hai bro your videos are more informative and understandable Thank you soo much',\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-07T11:28:31Z'},\n",
       " {'Comment_Id': 'UgyiTvvihw_rNXY3e8R4AaABAg',\n",
       "  'Video_Id': 'VfakvmAlwhU',\n",
       "  'Comment_Text': 'bro im getting server selection time out error what should i do?',\n",
       "  'Comment_Author': 'Rihana Parveen',\n",
       "  'Comment_Published': '2023-11-18T13:39:57Z'},\n",
       " {'Comment_Id': 'UgwpJWsGl7wXgkQnKxR4AaABAg',\n",
       "  'Video_Id': 'VfakvmAlwhU',\n",
       "  'Comment_Text': \"Bro i followed by your total concept but pgadmin4 doesn't inserting value showed....\",\n",
       "  'Comment_Author': 'Mohammed Faizal N',\n",
       "  'Comment_Published': '2023-11-15T13:46:47Z'},\n",
       " {'Comment_Id': 'Ugzdczw0UZ-U84CdAMZ4AaABAg',\n",
       "  'Video_Id': 'VfakvmAlwhU',\n",
       "  'Comment_Text': 'I can understand your situation bro.. atleast your videos are helping alot. Placements nalla pannungo ❤️💫',\n",
       "  'Comment_Author': 'Hudson Sylvestor',\n",
       "  'Comment_Published': '2023-11-10T21:28:29Z'},\n",
       " {'Comment_Id': 'UgxgskWIfemfXKXGUPV4AaABAg',\n",
       "  'Video_Id': 'VfakvmAlwhU',\n",
       "  'Comment_Text': 'Bro please update how to use streamlit to connect',\n",
       "  'Comment_Author': 'Nishanth Vijay',\n",
       "  'Comment_Published': '2023-11-03T16:26:00Z'},\n",
       " {'Comment_Id': 'UgzpL-vw2JtpZGZahBB4AaABAg',\n",
       "  'Video_Id': 'G4YlF8bBtLs',\n",
       "  'Comment_Text': 'Hi bro one doubt',\n",
       "  'Comment_Author': 'lovely subin',\n",
       "  'Comment_Published': '2023-11-09T10:04:33Z'},\n",
       " {'Comment_Id': 'Ugwhg6yR0WBipgCbb3R4AaABAg',\n",
       "  'Video_Id': 'G4YlF8bBtLs',\n",
       "  'Comment_Text': 'Hi bro am not able to connect postgresql will u pls help me',\n",
       "  'Comment_Author': 'Gvsanju',\n",
       "  'Comment_Published': '2023-11-04T20:02:58Z'},\n",
       " {'Comment_Id': 'UgwFoz6XtdJkBvKY6Xt4AaABAg',\n",
       "  'Video_Id': 'G4YlF8bBtLs',\n",
       "  'Comment_Text': \"Your phone number or WhatsApp number bro.... still can't connect to MongoDB\\n\\nDue date also over😢\",\n",
       "  'Comment_Author': 'Dhanush Raj',\n",
       "  'Comment_Published': '2023-11-02T05:52:14Z'},\n",
       " {'Comment_Id': 'Ugwg1j89ld2L2gRHGhF4AaABAg',\n",
       "  'Video_Id': 'G4YlF8bBtLs',\n",
       "  'Comment_Text': 'bro pls finish this playlist as soon as possible pls\\nthis is helping me to complete my project.but iam already in due..so if u finish this project completely pretty soon, it will be of great help.thankyou',\n",
       "  'Comment_Author': 'sriram ganesh',\n",
       "  'Comment_Published': '2023-11-01T15:01:36Z'},\n",
       " {'Comment_Id': 'Ugx0qCb8kCb46ls26i54AaABAg',\n",
       "  'Video_Id': '5TEauiYxpZk',\n",
       "  'Comment_Text': \"Hi, I didn't get python environment in vs code after writing hello world program and also i am unable to create kernel.\",\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-02T12:53:25Z'},\n",
       " {'Comment_Id': 'UgyU4pAHPebr2pCpNjJ4AaABAg',\n",
       "  'Video_Id': '5TEauiYxpZk',\n",
       "  'Comment_Text': \"Bro I've sent mail to you\",\n",
       "  'Comment_Author': 'Dhanush Raj',\n",
       "  'Comment_Published': '2023-10-31T10:29:01Z'},\n",
       " {'Comment_Id': 'UgwSWRok4XTuoQavtpB4AaABAg',\n",
       "  'Video_Id': '2IU9RpMzgAo',\n",
       "  'Comment_Text': 'Hello Bro, I Postgre SQL in Tables  \"channel\" is not created, I even refreshed the screen several times. What should I do?',\n",
       "  'Comment_Author': 'SNEHA M',\n",
       "  'Comment_Published': '2023-11-16T16:05:41Z'},\n",
       " {'Comment_Id': 'UgxlD7sGOoKV-sME6mx4AaABAg',\n",
       "  'Video_Id': '2IU9RpMzgAo',\n",
       "  'Comment_Text': 'Bro I got a name error on Mogo db  how to solve it can  u help me  yo solve it',\n",
       "  'Comment_Author': 'Ben Singh',\n",
       "  'Comment_Published': '2023-11-08T19:29:38Z'},\n",
       " {'Comment_Id': 'UgyUY2oN1Ma04OhCPit4AaABAg',\n",
       "  'Video_Id': '2IU9RpMzgAo',\n",
       "  'Comment_Text': 'Thank you soo much bro your videos are most use full for me, i learn more information from your videos thank you.',\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-06T19:39:30Z'},\n",
       " {'Comment_Id': 'UgzPhNmDiO0qRCUI3vN4AaABAg',\n",
       "  'Video_Id': '2IU9RpMzgAo',\n",
       "  'Comment_Text': 'Sir how to import in mysql workbench',\n",
       "  'Comment_Author': 'Praveen Raj',\n",
       "  'Comment_Published': '2023-11-01T15:39:36Z'},\n",
       " {'Comment_Id': 'UgyedMvnoI8W62aK70N4AaABAg',\n",
       "  'Video_Id': 'FGnZ3pUliCU',\n",
       "  'Comment_Text': 'Hello Bro!Youexplainign to insert for one channeldetails .But how to insert 10 channel details in mongodb.',\n",
       "  'Comment_Author': 'SNEHA M',\n",
       "  'Comment_Published': '2023-11-16T06:31:49Z'},\n",
       " {'Comment_Id': 'UgzCmBQyhBPWSXk4Zil4AaABAg',\n",
       "  'Video_Id': 'FGnZ3pUliCU',\n",
       "  'Comment_Text': 'Thanks bro your videos are most use full me thank you soo much',\n",
       "  'Comment_Author': 'Renugadevi Chakkarai',\n",
       "  'Comment_Published': '2023-11-06T12:41:00Z'},\n",
       " {'Comment_Id': 'UgzXYa4HhxW3zu0VXq54AaABAg',\n",
       "  'Video_Id': 'EXn3-jKNVFU',\n",
       "  'Comment_Text': \"Video_Count=item['contentDetails']['itemCount']  intha line la\\n\\n Video_Count=item['contentDetails']['itemCount'] )\\r\\n                                                    ^\\r\\nSyntaxError: positional argument follows keyword argument\\n\\nerror ku enna change panrathu bro?\",\n",
       "  'Comment_Author': 'Dhanush Raj',\n",
       "  'Comment_Published': '2023-10-29T08:08:50Z'},\n",
       " {'Comment_Id': 'UgxIeqsCUBRylZ4cUM94AaABAg',\n",
       "  'Video_Id': 'on-a5-77Y94',\n",
       "  'Comment_Text': 'Bro when I am typing \"len(comment_details)\" I am getting 0 comments.I wrote exactly the same code as you.',\n",
       "  'Comment_Author': 'SNEHA M',\n",
       "  'Comment_Published': '2023-11-15T13:44:08Z'},\n",
       " {'Comment_Id': 'UgzEvQsNi_5glN03zut4AaABAg',\n",
       "  'Video_Id': 'on-a5-77Y94',\n",
       "  'Comment_Text': 'eventhough if we provide maxResults set to 100 it is always returning 20 comments per video, did you fixed that?',\n",
       "  'Comment_Author': 'Kannan Kandasamy',\n",
       "  'Comment_Published': '2023-11-09T21:14:34Z'},\n",
       " {'Comment_Id': 'Ugwc0TT7GM4cYKJ_Xnh4AaABAg',\n",
       "  'Video_Id': 'on-a5-77Y94',\n",
       "  'Comment_Text': 'Httperror bro',\n",
       "  'Comment_Author': 'lovely subin',\n",
       "  'Comment_Published': '2023-11-09T15:04:22Z'},\n",
       " {'Comment_Id': 'Ugx_K8itCN320CnoHEd4AaABAg',\n",
       "  'Video_Id': 'on-a5-77Y94',\n",
       "  'Comment_Text': 'Super bro, it will helpful for us ❤',\n",
       "  'Comment_Author': 'NAVIN N',\n",
       "  'Comment_Published': '2023-11-01T08:36:13Z'},\n",
       " {'Comment_Id': 'UgyQ6u7-LRiEmVDSntB4AaABAg',\n",
       "  'Video_Id': 'on-a5-77Y94',\n",
       "  'Comment_Text': 'Bro, MongoDB la store panra video epo varum?',\n",
       "  'Comment_Author': 'Jose Asmino',\n",
       "  'Comment_Published': '2023-10-27T17:20:39Z'},\n",
       " {'Comment_Id': 'UgzX9smkBg-A8cSU1Dp4AaABAg',\n",
       "  'Video_Id': 'OM7Bsb9ZCTY',\n",
       "  'Comment_Text': 'runing time skip panna vendam broo....unga channel enku romba helpful ah eruku...thank you so much broooo....👌👌👏👏',\n",
       "  'Comment_Author': 'SANJAI_A',\n",
       "  'Comment_Published': '2023-11-07T07:31:41Z'},\n",
       " {'Comment_Id': 'Ugy_H1ZA6ovdiLvQ7wp4AaABAg',\n",
       "  'Video_Id': 'OM7Bsb9ZCTY',\n",
       "  'Comment_Text': 'Bro enaku http error 403 varuthu API key quota exceeded nu varuthu vera API key creat pani poten but apavum intha error adikadi varuthu what to do bro pls help on this...',\n",
       "  'Comment_Author': 'Sanjay SK',\n",
       "  'Comment_Published': '2023-10-31T18:25:21Z'},\n",
       " {'Comment_Id': 'UgySFLUCqdOW6uO_IR14AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'Finally, for checking when I enter \"len(video_ids)\" I am getting only 50 counts instead of 468 bro. What should I do?I did exactly as you told.',\n",
       "  'Comment_Author': 'SNEHA M',\n",
       "  'Comment_Published': '2023-11-14T18:05:12Z'},\n",
       " {'Comment_Id': 'UgzaLQqPmY-En9yXAo14AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'unga videos simply super...coding theriyamalea coding panren...need ur support..',\n",
       "  'Comment_Author': 'Vasunthara Jr',\n",
       "  'Comment_Published': '2023-11-09T16:22:45Z'},\n",
       " {'Comment_Id': 'UgzNvk9kxQTh6hE3KuB4AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'hi@datasciencetamil enaku type error nu varuthu bro...couldnt get it...ena panrathu',\n",
       "  'Comment_Author': 'Vasunthara Jr',\n",
       "  'Comment_Published': '2023-11-09T16:19:57Z'},\n",
       " {'Comment_Id': 'Ugxzz8_vi-BwgUUiIld4AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'How to extract information about different channels in one project?',\n",
       "  'Comment_Author': 'Pranav Bhawane',\n",
       "  'Comment_Published': '2023-11-05T14:58:45Z'},\n",
       " {'Comment_Id': 'UgwM3WBFHHAUHglqllB4AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'bro next_page_token=none potu erukurom? none ah erukapothu epdi funcation ahkuthu bro. kjm explain pana mudiuma?',\n",
       "  'Comment_Author': 'Naren . J',\n",
       "  'Comment_Published': '2023-11-01T09:35:39Z'},\n",
       " {'Comment_Id': 'UgxYRzFl6wj0JnZNXop4AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'Put the continuous videos',\n",
       "  'Comment_Author': 'Thanusha Ramesh',\n",
       "  'Comment_Published': '2023-10-25T03:25:03Z'},\n",
       " {'Comment_Id': 'UgwCbrpozYqVNqJrAet4AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'Mongodb la epdi upload panrathunu video podunga bro',\n",
       "  'Comment_Author': 'Suvalakshmi V',\n",
       "  'Comment_Published': '2023-10-22T06:39:46Z'},\n",
       " {'Comment_Id': 'UgxLnXytWeDGcSctXKR4AaABAg',\n",
       "  'Video_Id': '2cyfmA-R-Uw',\n",
       "  'Comment_Text': 'Bro streamlit epdi pandrathu video poduga bro',\n",
       "  'Comment_Author': 'Ad Adhi',\n",
       "  'Comment_Published': '2023-10-21T07:17:54Z'},\n",
       " {'Comment_Id': 'UgzQl4VBo_fa9DzUvQp4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': \"bro couldnt add googleapiclient - it shows No module named 'googleapiclient'\",\n",
       "  'Comment_Author': 'Priyanka Rangaswamy',\n",
       "  'Comment_Published': '2023-11-14T15:18:01Z'},\n",
       " {'Comment_Id': 'UgzvY3Iuq20BpIfiIiF4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'userbis in another person name but my api is in my name if i do in vs code to add python app data its in another name which not able get use api error wat to do in tat is there any video for tat kindly konjam solunga na',\n",
       "  'Comment_Author': 'pooja',\n",
       "  'Comment_Published': '2023-11-13T06:20:56Z'},\n",
       " {'Comment_Id': 'UgwMQnS31S9KeyzydqN4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'api key connection if i put it shows unknown apiname or version it means',\n",
       "  'Comment_Author': 'pooja',\n",
       "  'Comment_Published': '2023-11-12T14:15:44Z'},\n",
       " {'Comment_Id': 'Ugyb4F9U0YqxLGDkuvF4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'sir i get module not found error',\n",
       "  'Comment_Author': 'senthamil selvan',\n",
       "  'Comment_Published': '2023-11-10T06:40:38Z'},\n",
       " {'Comment_Id': 'UgyMprkwuIyVKnIvtLB4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'super bro thank u so much',\n",
       "  'Comment_Author': 'தோழர் Media',\n",
       "  'Comment_Published': '2023-11-09T05:07:21Z'},\n",
       " {'Comment_Id': 'Ugwi7KkjVtN37lDy3x54AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'File tokenize plz tell i mailed the photo',\n",
       "  'Comment_Author': 'Baraneetharan R',\n",
       "  'Comment_Published': '2023-11-04T19:03:09Z'},\n",
       " {'Comment_Id': 'UgzbFR4LBxewHKypwNR4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'sir...i got a error in return data.... syntax error : invalid syntax',\n",
       "  'Comment_Author': 'SANJAI_A',\n",
       "  'Comment_Published': '2023-11-04T17:15:22Z'},\n",
       " {'Comment_Id': 'UgzwW4L5NUdoGVBlK8l4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'bro how to get api key bezo the link you provide is not working',\n",
       "  'Comment_Author': 'Naren . J',\n",
       "  'Comment_Published': '2023-10-30T07:45:38Z'},\n",
       " {'Comment_Id': 'UgwZcuV3AxE8gMx2K-t4AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'Bro can we do the same in Google collab?',\n",
       "  'Comment_Author': 'Dhanush Raj',\n",
       "  'Comment_Published': '2023-10-27T05:53:05Z'},\n",
       " {'Comment_Id': 'UgzdNjFASKaa2x19_714AaABAg',\n",
       "  'Video_Id': 'r2sn478BKg4',\n",
       "  'Comment_Text': 'i got a error in channel information code',\n",
       "  'Comment_Author': 'Kalaivani M',\n",
       "  'Comment_Published': '2023-10-24T08:49:58Z'},\n",
       " {'Comment_Id': 'UgxR4MTiscRFc-1qIad4AaABAg',\n",
       "  'Video_Id': 'xBCx4PEZpfo',\n",
       "  'Comment_Text': 'couldnt create environment bro pls assist',\n",
       "  'Comment_Author': 'Priyanka Rangaswamy',\n",
       "  'Comment_Published': '2023-11-14T13:48:45Z'},\n",
       " {'Comment_Id': 'UgyOU6rMsn1BtZmYbjN4AaABAg',\n",
       "  'Video_Id': 'xBCx4PEZpfo',\n",
       "  'Comment_Text': 'bro jupyter laium streamlit install pananuma',\n",
       "  'Comment_Author': 'Vignesh',\n",
       "  'Comment_Published': '2023-11-06T10:43:12Z'},\n",
       " {'Comment_Id': 'UgzKpTwOasD2wXZsLQh4AaABAg',\n",
       "  'Video_Id': 'xBCx4PEZpfo',\n",
       "  'Comment_Text': 'Hi bro please share the instgram or LinkedIn links',\n",
       "  'Comment_Author': 'Aravind Gokul',\n",
       "  'Comment_Published': '2023-11-04T14:44:33Z'},\n",
       " {'Comment_Id': 'Ugz-b9_-vpME9qwKkj14AaABAg',\n",
       "  'Video_Id': 'xBCx4PEZpfo',\n",
       "  'Comment_Text': 'Are u currently at DS course?',\n",
       "  'Comment_Author': 'REVANTHRAGUL T',\n",
       "  'Comment_Published': '2023-11-03T01:12:58Z'},\n",
       " {'Comment_Id': 'UgxSDS-R4spWqEX_GCt4AaABAg',\n",
       "  'Video_Id': 'xBCx4PEZpfo',\n",
       "  'Comment_Text': 'can u upload in hindi??',\n",
       "  'Comment_Author': 'anjali shinde',\n",
       "  'Comment_Published': '2023-10-30T08:58:21Z'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get playlist ids\n",
    "def get_playlist_info(channel_id):\n",
    "    All_data = []\n",
    "    next_page_token = None\n",
    "    next_page = True\n",
    "    while next_page:\n",
    "\n",
    "        request = youtube.playlists().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']: \n",
    "            data={'PlaylistId':item['id'],\n",
    "                    'Title':item['snippet']['title'],\n",
    "                    'ChannelId':item['snippet']['channelId'],\n",
    "                    'ChannelName':item['snippet']['channelTitle'],\n",
    "                    'PublishedAt':item['snippet']['publishedAt'],\n",
    "                    'VideoCount':item['contentDetails']['itemCount']}\n",
    "            All_data.append(data)\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            next_page=False\n",
    "    return All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MongoDB Connection\n",
    "client = pymongo.MongoClient(\"mongodb+srv://snehamahesh1809:snehamahesh@cluster0.pmvxl2z.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db = client[\"Youtube_data\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to MongoDB\n",
    "\n",
    "def channel_details(channel_id):\n",
    "    ch_details = get_channel_info(channel_id)\n",
    "    pl_details = get_playlist_info(channel_id)\n",
    "    vi_ids = get_video_ids(channel_id)\n",
    "    vi_details = get_video_info(vi_ids)\n",
    "    com_details = get_comments_details(vi_ids)\n",
    "\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    coll1.insert_one({\"channel_information\":ch_details,\"playlist_information\":pl_details,\"video_information\":vi_details,\n",
    "                     \"comment_information\":com_details})\n",
    "    \n",
    "    return \"upload completed successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert=channel_details(\"UCuI5XcJYynHa5k_lqDzAgwQ\")#--Datascience tamil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only 10\n",
    "#insert=channel_details(\"UCdP7WjR7SGmo1TBSSUJ5Mtw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "##>vicky_edits   \n",
    "#insert=channel_details(\"UCGx7rPjOTx-Sm8u85KRI1wA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headhonk\n",
    "#insert=channel_details(\"UC1R2RJQD3GwgTQJpx-x45BA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TamilBusiness Podcast\n",
    "#insert=channel_details(\"UCy1lBBbXhtfzugF_LK2b6Yw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only 10          :\"UCdP7WjR7SGmo1TBSSUJ5Mtw\"\n",
    "#science with sam :\"UChGd9JY4yMegY6PxqpBjpRA\"\n",
    "#Mr Gk            :\"UC5cY198GU1MQMIPJgMkCJ_Q\"\n",
    "#vicky_edits      :\"UCGx7rPjOTx-Sm8u85KRI1wA\"\n",
    "#madhan gowri     :\"UCY6KjrDBN_tIRFT_QNqQbRQ\"\n",
    "#un signed        :\"UCXnDDUQyJpRfC98_ZRIuhZA\"\n",
    "#naked science    :\"UC8JT2m0mKEgvEtie3JNKwew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert=channel_details(\"UChGd9JY4yMegY6PxqpBjpRA\")#science with sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert=channel_details(\"UCJxYFTUdD2gPqG6g8lfm1Qw\")#MM Originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert=channel_details(\"UC_KRxRsrVu-gRhJT5E7-xaw\")#ALL in one tamil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert=channel_details(\"UCA94fhkrbOTB-uWXx8PjCkQ\")#Time Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert=channel_details(\"UC17Uwo5BkSTtGVbOkywJ7_Q\")#Future Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#only 10          :\"UCdP7WjR7SGmo1TBSSUJ5Mtw\"<--\n",
    "##>vicky_edits      :\"UCGx7rPjOTx-Sm8u85KRI1wA\"<--\n",
    "##>Channel3:Headhonk:UC1R2RJQD3GwgTQJpx-x45BA<--\n",
    "##DataScience Tamil:UCuI5XcJYynHa5k_lqDzAgwQ<--\n",
    "##Tamil Business Podcast:UCy1lBBbXhtfzugF_LK2b6Yw<--\n",
    "##Coffee Business Basics : UCELWEzJrhBTnOPlwGuQ2n7g <--\n",
    "##MM Originals:UCJxYFTUdD2gPqG6g8lfm1Qw\n",
    "##ALL in one tamil:UC_KRxRsrVu-gRhJT5E7-xaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table creation for channels,playlists, videos, comments\n",
    "def channels_table():\n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"1809\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists channels\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''create table if not exists channels(Channel_Name varchar(100),\n",
    "                        Channel_Id varchar(80) primary key, \n",
    "                        Subscription_Count bigint, \n",
    "                        Views bigint,\n",
    "                        Total_Videos int,\n",
    "                        Channel_Description text,\n",
    "                        Playlist_Id varchar(50))'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Channels Table alredy created\")\n",
    "    ch_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    df = pd.DataFrame(ch_list)\n",
    "    \n",
    "    for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT into channels(Channel_Name,\n",
    "                                                    Channel_Id,\n",
    "                                                    Subscription_Count,\n",
    "                                                    Views,\n",
    "                                                    Total_Videos,\n",
    "                                                    Channel_Description,\n",
    "                                                    Playlist_Id)\n",
    "                                        VALUES(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "            \n",
    "\n",
    "        values =(\n",
    "                row['Channel_Name'],\n",
    "                row['Channel_Id'],\n",
    "                row['Subscription_Count'],\n",
    "                row['Views'],\n",
    "                row['Total_Videos'],\n",
    "                row['Channel_Description'],\n",
    "                row['Playlist_Id'])\n",
    "        try:                     \n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()    \n",
    "        except:\n",
    "            st.write(\"Channels values are already inserted\")    \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"1809\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "mycursor=mydb.cursor()'''''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sql ='''CREATE TABLE EMPLOYEE1(\n",
    "   FIRST_NAME CHAR(20) NOT NULL,\n",
    "   LAST_NAME CHAR(20),\n",
    "   AGE INT,\n",
    "   SEX CHAR(1),\n",
    "   INCOME FLOAT\n",
    ")'''\n",
    "mycursor.execute(sql)\n",
    "print(\"Table created successfully........\")\n",
    "mydb.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ch_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    df = pd.DataFrame(ch_list)\n",
    "    \n",
    "    for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT into channels(Channel_Name,\n",
    "                                                    Channel_Id,\n",
    "                                                    Subscription_Count,\n",
    "                                                    Views,\n",
    "                                                    Total_Videos,\n",
    "                                                    Channel_Description,\n",
    "                                                    Playlist_Id)\n",
    "                                        VALUES(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "            \n",
    "\n",
    "        values =(\n",
    "                row['Channel_Name'],\n",
    "                row['Channel_Id'],\n",
    "                row['Subscription_Count'],\n",
    "                row['Views'],\n",
    "                row['Total_Videos'],\n",
    "                row['Channel_Description'],\n",
    "                row['Playlist_Id'])\n",
    "        try:                     \n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()    \n",
    "        except:\n",
    "            st.write(\"Channels values are already inserted\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'channel_information': {'Channel_Name': 'Data Science Tamil', 'Channel_Id': 'UCuI5XcJYynHa5k_lqDzAgwQ', 'Subscription_Count': '146', 'Views': '9342', 'Total_Videos': '18', 'Channel_Description': 'Dear Brothers and Sisters,\\n\\n         (Please clarify your doubts in Project doubt clarification session)\\n          Really SORRY for the INCONVENIENCE.\\n', 'Playlist_Id': 'UUuI5XcJYynHa5k_lqDzAgwQ'}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sneha\\OneDrive\\Desktop\\New folder (3)\\youtubetest.ipynb Cell 33\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sneha/OneDrive/Desktop/New%20folder%20%283%29/youtubetest.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m coll1 \u001b[39m=\u001b[39m db[\u001b[39m\"\u001b[39m\u001b[39mchannel_details\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sneha/OneDrive/Desktop/New%20folder%20%283%29/youtubetest.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m ch_data \u001b[39min\u001b[39;00m coll1\u001b[39m.\u001b[39mfind({},{\u001b[39m\"\u001b[39m\u001b[39m_id\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m0\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mchannel_information\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m1\u001b[39m}):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sneha/OneDrive/Desktop/New%20folder%20%283%29/youtubetest.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39;49m(ch_data)[\u001b[39m\"\u001b[39;49m\u001b[39mchannel_information\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#db = client[\"Youtube_data\"]\n",
    "#coll1 = db[\"channel_details\"]\n",
    "#for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "#    print(ch_data)[\"channel_information\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlists_table():\n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"1809\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists playlists\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''create table if not exists playlists(PlaylistId varchar(100) primary key,\n",
    "                        Title varchar(80), \n",
    "                        ChannelId varchar(100), \n",
    "                        ChannelName varchar(100),\n",
    "                        PublishedAt timestamp,\n",
    "                        VideoCount int\n",
    "                        )'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Playlists Table alredy created\")    \n",
    "\n",
    "\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 =db[\"channel_details\"]\n",
    "    pl_list = []\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "                pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    df = pd.DataFrame(pl_list)\n",
    "    \n",
    "    for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT into playlists(PlaylistId,\n",
    "                                                    Title,\n",
    "                                                    ChannelId,\n",
    "                                                    ChannelName,\n",
    "                                                    PublishedAt,\n",
    "                                                    VideoCount)\n",
    "                                        VALUES(%s,%s,%s,%s,%s,%s)'''            \n",
    "        values =(\n",
    "                row['PlaylistId'],\n",
    "                row['Title'],\n",
    "                row['ChannelId'],\n",
    "                row['ChannelName'],\n",
    "                row['PublishedAt'],\n",
    "                row['VideoCount'])\n",
    "                                     \n",
    "    try:\n",
    "        cursor.execute(insert_query,values)\n",
    "        mydb.commit()   \n",
    "    except:\n",
    "        st.write(\"Playlists values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videos_table():\n",
    "\n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "                user=\"postgres\",\n",
    "                password=\"1809\",\n",
    "                database= \"youtube_data\",\n",
    "                port = \"5432\"\n",
    "                )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists videos\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''create table if not exists videos(\n",
    "                        Channel_Name varchar(150),\n",
    "                        Channel_Id varchar(100),\n",
    "                        Video_Id varchar(50) primary key, \n",
    "                        Title varchar(150), \n",
    "                        Tags text,\n",
    "                        Thumbnail varchar(225),\n",
    "                        Description text, \n",
    "                        Published_Date timestamp,\n",
    "                        Duration interval, \n",
    "                        Views bigint, \n",
    "                        Likes bigint,\n",
    "                        Comments int,\n",
    "                        Favorite_Count int, \n",
    "                        Definition varchar(10), \n",
    "                        Caption_Status varchar(50) \n",
    "                        )''' \n",
    "                        \n",
    "        cursor.execute(create_query)             \n",
    "        mydb.commit()\n",
    "    except:\n",
    "        (\"Videos Table alrady created\")\n",
    "\n",
    "    vi_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for vi_data in coll1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "    df2 = pd.DataFrame(vi_list)\n",
    "        \n",
    "    \n",
    "    for index, row in df2.iterrows():\n",
    "        insert_query = '''\n",
    "                    INSERT INTO videos (Channel_Name,\n",
    "                        Channel_Id,\n",
    "                        Video_Id, \n",
    "                        Title, \n",
    "                        Tags,\n",
    "                        Thumbnail,\n",
    "                        Description, \n",
    "                        Published_Date,\n",
    "                        Duration, \n",
    "                        Views, \n",
    "                        Likes,\n",
    "                        Comments,\n",
    "                        Favorite_Count, \n",
    "                        Definition, \n",
    "                        Caption_Status \n",
    "                        )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\n",
    "                '''\n",
    "        values = (\n",
    "                    row['Channel_Name'],\n",
    "                    row['Channel_Id'],\n",
    "                    row['Video_Id'],\n",
    "                    row['Title'],\n",
    "                    row['Tags'],\n",
    "                    row['Thumbnail'],\n",
    "                    row['Description'],\n",
    "                    row['Published_Date'],\n",
    "                    row['Duration'],\n",
    "                    row['Views'],\n",
    "                    row['Likes'],\n",
    "                    row['Comments'],\n",
    "                    row['Favorite_Count'],\n",
    "                    row['Definition'],\n",
    "                    row['Caption_Status'])\n",
    "                                \n",
    "        try:    \n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "        except:\n",
    "            st.write(\"videos values already inserted in the table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_table():\n",
    "    \n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "                user=\"postgres\",\n",
    "                password=\"1809\",\n",
    "                database= \"youtube_data\",\n",
    "                port = \"5432\"\n",
    "                )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists comments\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE if not exists comments(Comment_Id varchar(100) primary key,\n",
    "                       Video_Id varchar(80),\n",
    "                       Comment_Text text, \n",
    "                       Comment_Author varchar(150),\n",
    "                       Comment_Published timestamp)'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "        \n",
    "    except:\n",
    "        st.write(\"Commentsp Table already created\")\n",
    "\n",
    "    com_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for com_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        for i in range(len(com_data[\"comment_information\"])):\n",
    "            com_list.append(com_data[\"comment_information\"][i])\n",
    "    df3 = pd.DataFrame(com_list)\n",
    "\n",
    "\n",
    "    for index, row in df3.iterrows():\n",
    "            insert_query = '''\n",
    "                INSERT INTO comments (Comment_Id,\n",
    "                                      Video_Id ,\n",
    "                                      Comment_Text,\n",
    "                                      Comment_Author,\n",
    "                                      Comment_Published)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "\n",
    "            '''\n",
    "            values = (\n",
    "                row['Comment_Id'],\n",
    "                row['Video_Id'],\n",
    "                row['Comment_Text'],\n",
    "                row['Comment_Author'],\n",
    "                row['Comment_Published']\n",
    "            )\n",
    "    \n",
    "            cursor.execute(insert_query,values)\n",
    "    mydb.commit()\n",
    "            \n",
    "    st.write(\"This comments are already exist in comments table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:24:04.844 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\sneha\\OneDrive\\Desktop\\New folder (3)\\.venv\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "comments_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables():\n",
    "    channels_table()\n",
    "    playlists_table()\n",
    "    videos_table()\n",
    "    comments_table()\n",
    "    return \"Tables Created successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "    ch_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"] \n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    channels_table = st.dataframe(ch_list)\n",
    "    return channels_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlists_table():\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 =db[\"channel_details\"]\n",
    "    pl_list = []\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "                pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    playlists_table = st.dataframe(pl_list)\n",
    "    return playlists_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():\n",
    "    vi_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll2 = db[\"channel_details\"]\n",
    "    for vi_data in coll2.find({},{\"_id\":0,\"video_information\":1}):\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "    videos_table = st.dataframe(vi_list)\n",
    "    return videos_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streamlit Part\n",
    "def show_comments_table():\n",
    "    com_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll3 = db[\"channel_details\"]\n",
    "    for com_data in coll3.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        for i in range(len(com_data[\"comment_information\"])):\n",
    "            com_list.append(com_data[\"comment_information\"][i])\n",
    "    comments_table = st.dataframe(com_list)\n",
    "    return comments_table\n",
    "with st.sidebar:\n",
    "    st.title(\":red[YOUTUBE DATA HARVESTING AND WAREHOUSING]\")\n",
    "    st.header(\"SKILL TAKE AWAY\")\n",
    "    st.caption('Python scripting')\n",
    "    st.caption(\"Data Collection\")\n",
    "    st.caption(\"MongoDB\")\n",
    "    st.caption(\"API Integration\")\n",
    "    st.caption(\" Data Managment using MongoDB and SQL\")\n",
    "    \n",
    "channel_id = st.text_input(\"Enter the Channel id\")\n",
    "channels = channel_id.split(',')\n",
    "channels = [ch.strip() for ch in channels if ch]\n",
    "\n",
    "if st.button(\"Collect and Store data\"):\n",
    "    for channel in channels: \n",
    "        ch_ids = []\n",
    "        db = client[\"Youtube_data\"]\n",
    "        coll1 = db[\"channel_details\"]\n",
    "        for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "            ch_ids.append(ch_data[\"channel_information\"][\"Channel_Id\"])\n",
    "        if channel in ch_ids:\n",
    "            st.success(\"Channel details of the given channel id: \" + channel + \" already exists\")\n",
    "        else:\n",
    "            output = channel_details(channel)\n",
    "            st.success(output)\n",
    "            \n",
    "if st.button(\"Migrate to SQL\"):\n",
    "    display = tables()\n",
    "    st.success(display)\n",
    "    \n",
    "show_table = st.radio(\"SELECT THE TABLE FOR VIEW\",(\":green[channels]\",\":orange[playlists]\",\":red[videos]\",\":blue[comments]\"))\n",
    "\n",
    "if show_table == \":green[channels]\":\n",
    "    show_channels_table()\n",
    "elif show_table == \":orange[playlists]\":\n",
    "    show_playlists_table()\n",
    "elif show_table ==\":red[videos]\":\n",
    "    show_videos_table()\n",
    "elif show_table == \":blue[comments]\":\n",
    "    show_comments_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL connection\n",
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"1809\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = st.selectbox(\n",
    "    'Please Select Your Question',\n",
    "    ('1. All the videos and the Channel Name',\n",
    "     '2. Channels with most number of videos',\n",
    "     '3. 10 most viewed videos',\n",
    "     '4. Comments in each video',\n",
    "     '5. Videos with highest likes',\n",
    "     '6. likes of all videos',\n",
    "     '7. views of each channel',\n",
    "     '8. videos published in the year 2022',\n",
    "     '9. average duration of all videos in each channel',\n",
    "     '10. videos with highest number of comments'))\n",
    "\n",
    "     \n",
    "if question == '1. All the videos and the Channel Name':\n",
    "    query1 = \"select Title as videos, Channel_Name as ChannelName from videos;\"\n",
    "    cursor.execute(query1)\n",
    "    mydb.commit()\n",
    "    t1=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t1, columns=[\"Video Title\",\"Channel Name\"]))\n",
    "\n",
    "elif question == '2. Channels with most number of videos':\n",
    "    query2 = \"select Channel_Name as ChannelName,Total_Videos as NO_Videos from channels order by Total_Videos desc;\"\n",
    "    cursor.execute(query2)\n",
    "    mydb.commit()\n",
    "    t2=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t2, columns=[\"Channel Name\",\"No Of Videos\"]))\n",
    "\n",
    "elif question == '3. 10 most viewed videos':\n",
    "    query3 = '''select Views as views , Channel_Name as ChannelName,Title as VideoTitle from videos \n",
    "                        where Views is not null order by Views desc limit 10;'''\n",
    "    cursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    t3 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t3, columns = [\"views\",\"channel Name\",\"video title\"]))\n",
    "\n",
    "elif question == '4. Comments in each video':\n",
    "    query4 = \"select Comments as No_comments ,Title as VideoTitle from videos where Comments is not null;\"\n",
    "    cursor.execute(query4)\n",
    "    mydb.commit()\n",
    "    t4=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t4, columns=[\"No Of Comments\", \"Video Title\"]))\n",
    "\n",
    "elif question == '5. Videos with highest likes':\n",
    "    query5 = '''select Title as VideoTitle, Channel_Name as ChannelName, Likes as LikesCount from videos \n",
    "                       where Likes is not null order by Likes desc;'''\n",
    "    cursor.execute(query5)\n",
    "    mydb.commit()\n",
    "    t5 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t5, columns=[\"video Title\",\"channel Name\",\"like count\"]))\n",
    "\n",
    "elif question == '6. likes of all videos':\n",
    "    query6 = '''select Likes as likeCount,Title as VideoTitle from videos;'''\n",
    "    cursor.execute(query6)\n",
    "    mydb.commit()\n",
    "    t6 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t6, columns=[\"like count\",\"video title\"]))\n",
    "\n",
    "elif question == '7. views of each channel':\n",
    "    query7 = \"select Channel_Name as ChannelName, Views as Channelviews from channels;\"\n",
    "    cursor.execute(query7)\n",
    "    mydb.commit()\n",
    "    t7=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t7, columns=[\"channel name\",\"total views\"]))\n",
    "\n",
    "elif question == '8. videos published in the year 2022':\n",
    "    query8 = '''select Title as Video_Title, Published_Date as VideoRelease, Channel_Name as ChannelName from videos \n",
    "                where extract(year from Published_Date) = 2022;'''\n",
    "    cursor.execute(query8)\n",
    "    mydb.commit()\n",
    "    t8=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t8,columns=[\"Name\", \"Video Publised On\", \"ChannelName\"]))\n",
    "\n",
    "elif question == '9. average duration of all videos in each channel':\n",
    "    query9 =  \"SELECT Channel_Name as ChannelName, AVG(Duration) AS average_duration FROM videos GROUP BY Channel_Name;\"\n",
    "    cursor.execute(query9)\n",
    "    mydb.commit()\n",
    "    t9=cursor.fetchall()\n",
    "    t9 = pd.DataFrame(t9, columns=['ChannelTitle', 'Average Duration'])\n",
    "    T9=[]\n",
    "    for index, row in t9.iterrows():\n",
    "        channel_title = row['ChannelTitle']\n",
    "        average_duration = row['Average Duration']\n",
    "        average_duration_str = str(average_duration)\n",
    "        T9.append({\"Channel Title\": channel_title ,  \"Average Duration\": average_duration_str})\n",
    "    st.write(pd.DataFrame(T9))\n",
    "\n",
    "elif question == '10. videos with highest number of comments':\n",
    "    query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos \n",
    "                       where Comments is not null order by Comments desc;'''\n",
    "    cursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t10, columns=['Video Title', 'Channel Name', 'NO Of Comments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
